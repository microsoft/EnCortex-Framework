{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 1: Solving Battery Arbitrage Problem (Cost and Carbon Optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our partner, a global energy provider is deploying Li-ion batteries at their consumer premises to either maximize economic profit (increase cost savings by charging/discharging the battery at off-peak/peak price periods) or maximize environmental impact (reduce overall carbon footprint by charging/discharging the battery based on usage of renewable/non-renewable energy sources from the utility grid). \n",
    "\n",
    "<!-- Thus, it is important to optimize the management and scheduling of these batteries (when to charge or discharge) to maximize the objective. Mathematically, \n",
    "$$\n",
    "max \\sum_{t=1}^{T}(\\omega_{carbon}{Em}_{t} + \\omega_{cost}{Cost}_{t} - \\omega_{deg}{DegCost}_{t})\n",
    "$$ -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src='../_static/energy_arbitrage.png' height = 200 width = 600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief look into EnCortex implementation details\n",
    "\n",
    "1. The Entities used here are `Battery` and `Grid`, which is an umbrella term for a utility grid.\n",
    "2. The *action space* or the *decision* in this scenario is to either charge the battery, discharge the battery or letting it stay idle.\n",
    "3. The supported optimizers are `Mixed-Integer Linear Programming`, `Reinforcement Learning`, `Simulated Annealing`\n",
    "4. The data in this scenario is only present with the `Grid` entity. The `csv` file format is illustrated in the table below:\n",
    "\n",
    "| timestamps          | prices | emissions |\n",
    "|---------------------|--------|-----------|\n",
    "| 2019-10-20 00:00:00 | 40.47  | 116.0     |\n",
    "| ...                 | ...    | ...       |\n",
    "\n",
    "For more details, please refer to `Section 5.1` in our paper: [EnCortex](./_static/nsdi23fall-paper705.pdf)\n",
    "\n",
    "Here, we aim to use the below objective function:\n",
    "\n",
    "$$\n",
    "    max \\sum_{t=1}^{T}(\\omega_{carbon}{Em}_{t} + \\omega_{cost}{Cost}_{t} - \\omega_{deg}{DegCost}_{t})\n",
    "$$\n",
    "\n",
    "where $\\omega_{field}$ corresponds to relative weight/importance of that field/attribute. The field here are cost savings($Cost_t$), carbon emission savings($Em_t$) and degradation cost associated with the battery($DegCost_t$). The $T$ corresponds to the horizon over which the objective function is maximized. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : Import the libraries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, first we import all the general as well as encortex based abstractions necessary to solve the problem statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import external libraries and some modules\n",
    "import numpy as np\n",
    "from rsome import ro\n",
    "from rsome.lp import Affine\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from encortex.contract import Contract\n",
    "from encortex.decision_unit import DecisionUnit\n",
    "from encortex.environments.battery_arbitrage import BatteryArbitrageMILPEnv \n",
    "from encortex.environments.battery_arbitrage import BatteryArbitrageRLEnv\n",
    "from encortex.grid import Grid\n",
    "from encortex.sources import Battery\n",
    "from encortex.optimizers.milp import MILPOptimizer\n",
    "from encortex.optimizers.rl import EnCortexRLOptimizer\n",
    "from encortex.data import MarketData\n",
    "from encortex.backend import DFBackend\n",
    "from encortex.callbacks.env_callback import EnvCallback\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "from stable_baselines3.common.logger import HumanOutputFormat, KVWriter, Logger\n",
    "from encortex.utils.mlflow_utils import MLflowOutputFormat\n",
    "\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "import ipywidgets as widgets\n",
    "from itertools import repeat\n",
    "InteractiveShell.ast_node_interactivity=\"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Inputs from the User "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we present certain configurable parameters, that the user can tweak and experiment to improve the performance for the scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Optimization Algorithms :  We support multiple algorithms such as ,\n",
    "    - Mixed Integer Linear Programming (MILP) :There are various solvers which can be used for MILP. We support : OR-Tools (\"ort\"), Gurobi (\"grb\"), Cplex (\"cpx\"), CyLP (\"clp\"), ECOS (\"eco\"), MOSEK (\"msk\") and so on. We recommend using OR-Tools as a free open source solver producing similar reproducible correct solution. Gurobi is the other recommended solver which although commercial, takes lesser solving time to produce similar result.\n",
    "    \n",
    "    - Simulated Annealing (SA) : Simulated Annealing does not require any solver.\n",
    "    \n",
    "    - Deep Reinforcement Learning (DRL) :  The following cell shows how to run Reinforcement Learning. Deep Q-Networks (dqn) is used for the problem statement given here. We support multiple other reinforcement learning algorithms like :  Advantage Actor Critic (a2c), Proximal Policy Optimization (PPO) and so on. Therefore the respective solver names to be used are :  \"dqn\", \"a2c\", \"PPO\". Check for all the optimizers that can be used from [here](../encortex/encortex.optimizers.battery_arbitrage_optimizer.rst).\n",
    "\n",
    "    The user can use the following flags to specify the type of algorithm to be used and mention the solver name to run the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the type of optimization to be used:\n",
    "milp_flag = True \n",
    "solver = \"grb\" #the algorithm to be used\n",
    "\n",
    "# In order to use RL:  \n",
    "# milp_flag = True \n",
    "# solver = \"grb\" #the algorithm to be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Selection of Objectives: An user can choose to optimize for any combination of the following objectives by providing the relative importance weights as a float value between 0.0 to 1.0:\n",
    "    - Carbon Optimization\n",
    "    - Cost Optimization\n",
    "\n",
    "    For example, in the following cell, equal importance has been given to emission and price values, thus the algorithms will optimize for both the objectives leading to optimal schedules that the energy operator can take by which both increasing profits and reducing carbon footprints can be taken care of.\n",
    "\n",
    "    Because of the high variability in the data, it is not always intuitive to provide equal importance to both emissions and prices so as to lead to optimal savings. For this, we use Pareto Optimization curves to come to a single point of optimality, as discussed in our Paper.\n",
    "    \n",
    "    Since batteries perform a limited number of cycles during their lifetime, we consider an accurate battery degradation model to model the battery's lifetime. Hence, the Degradation importance weightage is also provided in addition to the above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#provide optimization weights for the objectives\n",
    "omega = 0.5\n",
    "\n",
    "# # Cost Optimization\n",
    "# omega = 0.0\n",
    "\n",
    "# # Carbon Optimization\n",
    "# omega = 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Battery Configurations: An user can run several experiments by tweaking the battery configurations. Following are the battery configurations which are left to user for configurable inputs:\n",
    "\n",
    "    - storage_capacity : the battery capacity (in kWh)\n",
    "    - efficiency : here, charging and discharging efficiency (in %) taken the same/ if different take it differently \n",
    "    - depth_of_discharge : the maximum discharge (in %) percentage that can happen at a time, here 90%\n",
    "    - soc_minimum : the minimum state of charge of the battery, below which the battery should not be explored\n",
    "    - timestep : battery decision time steps\n",
    "    - degradation_flag : whether to have degradation model in place or not for the batteries \n",
    "    - min_battery_capacity_factor : the battery capacity reduction percentage due to degradation, below which if capacity reduces due to overuse, battery does not stay at good optimal health\n",
    "    - battery_cost_per_kWh : the battery replacement cost (in $/kWh)\n",
    "    - reduction_coefficient : after every charge-discharge cycles over a certain period, the battery capacity reduced by the reduction coefficienct \n",
    "    - degradation_period_in_days : the period after which battery degrades\n",
    "    - action : battery actions, Here the battery can take 3 different actions {Charge/Discharge/Stay idle} at different power rates.\n",
    "    - soc_initial : initial state of charge of the battery to run the test experiments\n",
    "    - test_flag : the flag initiates random initial state of charge of the battery during training runs/experiments to avoid overfitting\n",
    "    - schedule: Schedule at which these actions must be executed at\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrun experiments for the following battery configurations\\nelements in the list denote different batteries/battery configurations to be used in the scenario together (here just 1 element indicating 1 battery being used)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "run experiments for the following battery configurations\n",
    "elements in the list denote different batteries/battery configurations to be used in the scenario together (here just 1 element indicating 1 battery being used)\n",
    "'''\n",
    "timestep=(60, \"m\")\n",
    "storage_capacity=10\n",
    "charging_efficiency=1.\n",
    "discharging_efficiency=1.\n",
    "soc_initial=0.2\n",
    "depth_of_discharge=90\n",
    "soc_minimum=0.1\n",
    "degradation_flag=False\n",
    "min_battery_capacity_factor=0.8\n",
    "battery_cost_per_kWh=200.\n",
    "reduction_coefficient=0.0\n",
    "degradation_period=10\n",
    "test_flag=True\n",
    "schedule=\"0 * * * *\"\n",
    "seed = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Instantiating Objects of the required abstractions from the framework:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the energy operator determines the entities involved in the scenario and uses the framework provided abstractions for the same. Following are the two entities used here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Battery Entity : \n",
    "We inherit the storage class to define a Li-ion battery entity. In this scenario, we define three battery actions: charge at max rate, discharge at max rate or stay idle. The energy operator populates the parameter values based on their battery configuration and instantiate an EnCortex-Battery object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrun experiments for the following battery configurations\\nelements in the list denote different batteries/battery configurations to be used in the scenario together (here just 1 element indicating 1 battery being used)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "run experiments for the following battery configurations\n",
    "elements in the list denote different batteries/battery configurations to be used in the scenario together (here just 1 element indicating 1 battery being used)\n",
    "'''\n",
    "battery = Battery(\n",
    "    timestep=timestep,\n",
    "    name=\"Battery\",\n",
    "    id=id,\n",
    "    description=\"Battery\",\n",
    "    storage_capacity=storage_capacity,\n",
    "    charging_efficiency=charging_efficiency,\n",
    "    discharging_efficiency=discharging_efficiency,\n",
    "    soc_initial=soc_initial,\n",
    "    depth_of_discharge=depth_of_discharge,\n",
    "    soc_minimum=soc_minimum,\n",
    "    degradation_flag=degradation_flag,\n",
    "    min_battery_capacity_factor=min_battery_capacity_factor,\n",
    "    battery_cost_per_kWh=battery_cost_per_kWh,\n",
    "    reduction_coefficient=reduction_coefficient,\n",
    "    degradation_period=degradation_period,\n",
    "    test_flag=test_flag,\n",
    "    schedule=schedule,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Utility Grid: Since Energy Arbitrage does not require any bidding decisions in the market, we modify the real-time market entity to a simplified real-time market entity that captures just the real-time market prices along with the carbon footprint information. This shows the utility of our abstractions, which allow seamless modification/extension of the definitions based on the scenario. Check into the encortex references to know more about the argument details.\n",
    "\n",
    "\n",
    "Now, this entity requires loading data of the market prices and the carbon emissions. There are two ways of using the data:\n",
    "\n",
    "- __Download data__ from any public source (here, we share an onedrive [link](https://microsoftapc-my.sharepoint.com/:f:/g/personal/t-vballoli_microsoft_com/Evd4JIo7F4hFjI9Y_MJPVEYBYc4iP2i-OND1gfoCx3xiIQ?e=hhzg4M) to show the functionality of the same), create a folder named data and add your train.csv and test.csv files for both forecast and actual data.   \n",
    "\n",
    "- Using __Data Loaders__ of Encortex: We have some publicly available data support in the framework.(The commented section shows the use of Data Loaders here). Also, one needs to replace all the forecast_df and actual_df with forecast_df.data and actual_df.data here. The existing data loaders takes in 3 user-specific arguments:\n",
    "    - train: A flag saying whether training/test data to load\n",
    "    - forecasts: A flag saying whether experiments are to be run on forecasts/actuals\n",
    "    - forecast_type: A string specifyng the type of forecast:\n",
    "        - noise : Adding noise to the actual values and treating that as forecasts\n",
    "        - smoothing : Smoothing the actual values and using that as forecasts\n",
    "        - yesterdays : assuming yesterday's actual data as forecasts for today's data\n",
    "        - meanprev : assuming mean of previous n days as forecasts for today's data (default)\n",
    "        - lgbm : using light gradient boosting machine to produce forecasts\n",
    "        - nbeats: using nbeats model to produce forecasts\n",
    "        - auto : if forecasts already available load that instead\n",
    "\n",
    "Since schedules are made ahead of time, accurate forecasts are required for producing optimal decisions. We recommend using nbeats as a forecast type for this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = pd.read_csv(\"/home/akshayn/main_encortex//data/UK_data_2020_meanprev_shortened.csv\")\n",
    "actual_df = pd.read_csv(\"/home/akshayn/main_encortex//data/UK_data_2020_actuals_shortened.csv\")\n",
    "\n",
    "forecast_df[['emissions', 'prices']]  = forecast_df[['emissions', 'prices']].apply(lambda x: np.float32(x))\n",
    "actual_df[['emissions', 'prices']]  = actual_df[['emissions', 'prices']].apply(lambda x: np.float32(x))\n",
    "\n",
    "grid_data = MarketData.parse_backend(\n",
    "    3, True, 3, 3, np.timedelta64(5, 'm'), price_forecast=DFBackend(forecast_df['prices'], forecast_df['timestamps']),\n",
    "    price_actual=DFBackend(actual_df['prices'], actual_df['timestamps']),\n",
    "    carbon_emissions_forecast=DFBackend(forecast_df['emissions'], forecast_df['timestamps']),\n",
    "    carbon_emissions_actual=DFBackend(actual_df['emissions'], actual_df['timestamps']),\n",
    "    carbon_prices_forecast=DFBackend(forecast_df['prices'], forecast_df['timestamps']),\n",
    "    carbon_prices_actual=DFBackend(actual_df['prices'], actual_df['timestamps']),\n",
    "    volume_forecast=DFBackend(None, None),\n",
    "    volume_actual=DFBackend(None, None), \n",
    ")\n",
    "grid = Grid(\n",
    "    timestep=(60, \"m\"),\n",
    "    name=\"Grid\",\n",
    "    id=3,\n",
    "    description=\"Grid\",\n",
    "    bid_start_time_schedule=\"0 * * * *\",\n",
    "    bid_window=np.timedelta64(0, \"h\"),\n",
    "    commit_start_schedule=(0, \"h\"),\n",
    "    commit_end_schedule=(0, \"h\"),\n",
    "    schedule=\"0 * * * *\",\n",
    "    data=grid_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Creating Decision units for the problem statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision units are built based on the entities and contracts associated with a particular producer. Contracts define the flow of energy between 2 entities in the framework. We use a graph representation of entities as nodes and contracts as edges to identify decision units. A decision unit generates critical information on the schedule and the associated actions based on the included contracts/entities.\n",
    "\n",
    "Here, for this scenario, contracts are between the grid and the batteries installed near to the consumer, and the decision unit is built on top of it(see line 5 in the cell below). The contract is bidirection since power can flow both ways between a battery and a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract = Contract(\n",
    "    contractor = battery,\n",
    "    contractee = grid,\n",
    "    bidirectional =  True\n",
    ")\n",
    "du = DecisionUnit(contracts = [contract])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Function to Store Results in a dataframe and then later to csv format:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump results into dataframes for later visualizations - \n",
    "- battery_soc_list: stores the current list of state of charge values for MILP\n",
    "- action_list : list of actions: charging/discharging/idle taken by the optimizer for a step\n",
    "- power_list: power associated with the action taken by the optimization algorithm\n",
    "- carbon_intensity_list: Actual carbon emission intensity values in gCO2eq/kWh\n",
    "- price_intensity_list: Actual price values in $\n",
    "- reward_list: List of rewards received for taking actions in particular states\n",
    "- carbon_savings_forecast_list : Carbon savings done due to the action taken for a particular state at a certain timestamp\n",
    "- price_savings_forecast_list : Price savings due to the action taken for a particular state at a certain timestamp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(\n",
    "    battery_soc_list, \n",
    "    action_list, \n",
    "    power_list, \n",
    "    carbon_intensity_list,\n",
    "    price_intensity_list,\n",
    "    carbon_savings_list,\n",
    "    price_savings_list,\n",
    "    reward_list, \n",
    "    carbon_savings_forecast_list, \n",
    "    price_savings_forecast_list\n",
    "):\n",
    "    df=pd.DataFrame()\n",
    "    df.insert(loc=0, column='Current_SOC', value=battery_soc_list)\n",
    "    df.insert(loc=1, column='Predicted_Action', value=action_list)\n",
    "    df.insert(loc=2, column='Predicted_Power_Action', value=power_list)\n",
    "    df.insert(loc=3, column='Carbon_emissions', value=carbon_intensity_list)\n",
    "    df.insert(loc=4, column='Carbon_savings', value=carbon_savings_list)\n",
    "    df.insert(loc=5, column='Forecast_Carbon_savings', value=carbon_savings_forecast_list)\n",
    "    df.insert(loc=6, column='Price_emissions', value=price_intensity_list)\n",
    "    df.insert(loc=7, column='Price_savings', value=price_savings_list)\n",
    "    df.insert(loc=8, column='Forecast_Price_savings', value=price_savings_forecast_list)\n",
    "    df.insert(loc=9, column='Reward', value=reward_list)  \n",
    "    return df\n",
    "\n",
    "#store the results into results folder\n",
    "country = \"UK\" # change it to the respective country name based on the grid's price/emissions data\n",
    "dir = os.getcwd()\n",
    "dir_path = os.path.join(dir, f'results_{country}/')\n",
    "\n",
    "if not os.path.isdir(dir_path):\n",
    "    os.mkdir(dir_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akshayn/main_encortex/docs/notebooks\n"
     ]
    }
   ],
   "source": [
    "dir = os.getcwd()\n",
    "print(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Instantiate the environment object from the scenario specific environment class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment forms a key layer in the EnCortex architecture to provide data and state information (state space) from entities that are needed to make a decision (action space) and a central point to orchestrate all the required decisions based on the schedule. \n",
    "\n",
    "EnCortex supports some of the common scenario based environments which can be easily extended to other similar custom scenarios by the energy operators. BatteryArbitrageScenarioEnv is one of the supported environments by EnCortex. Check here to know more details. The step_time_difference is another user-configurable parameter which says about the optimization step to be taken. For MILP, the optimum result comes when the step time difference is set similar to the timestep parameter. For Reinforcement Learning, it is a mandate to set it equal to the timestep else the action size increases which leads to erroneous learning by the agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInstantiate an environment object from the scenario specific environment class \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mt-vballoli\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/akshayn/main_encortex/docs/notebooks/wandb/run-20230129_041459-3nemlp3c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/t-vballoli/main_encortex-docs_notebooks/runs/3nemlp3c\" target=\"_blank\">lunar-snake-3</a></strong> to <a href=\"https://wandb.ai/t-vballoli/main_encortex-docs_notebooks\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Instantiate an environment object from the scenario specific environment class \n",
    "'''\n",
    "if milp_flag:\n",
    "        env = BatteryArbitrageMILPEnv(\n",
    "                decision_unit= du,\n",
    "                start_time = np.datetime64(\"2020-01-01T00:00\"),\n",
    "                seed = seed,\n",
    "                callbacks=[],\n",
    "                omega= omega,\n",
    "        )\n",
    "else:\n",
    "        env = BatteryArbitrageRLEnv(\n",
    "                decision_unit = du, \n",
    "                start_time = np.datetime64(\"2020-01-01T00:00\"), \n",
    "                seed = seed, \n",
    "                callbacks=[], \n",
    "                action_window=np.timedelta64(1, 'h'), \n",
    "                future_window=np.timedelta64(24, 'h')\n",
    "        )\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Training Pipeline for the algorithms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is only for RL and testing code can be split into 3 sections of RL, MILP, SA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, set the seed. This helps reproucing the results in the same machine, but still across different machine it does not guarantee to produce same result. The extreme noisy learning pattern, large amount of hyperparameter tuning, unpredictability and unexplainability of the RL agents add to the demerits of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting a seed for reproducibility of experiment results:\n",
    "pl.seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training in RL begins here, where we instantiate the DRLBattOpt based optimizer object and then save the best trained model to automatically created model_checkpoints folder for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTraining Pipeline for RL:\\nThe code in this cell helps to train a RL model, but there could be issues in trying it out in the jupyter cell. \\nHence we also provide a separate training script namely training_RL.py, try that out if the jupyter cell does not work.\\n\\nDuring testing just the load the model saved from the training script\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Training Pipeline for RL:\n",
    "The code in this cell helps to train a RL model, but there could be issues in trying it out in the jupyter cell. \n",
    "Hence we also provide a separate training script namely training_RL.py, try that out if the jupyter cell does not work.\n",
    "\n",
    "During testing just the load the model saved from the training script\n",
    "'''\n",
    "if not (milp_flag):\n",
    "    opt = EnCortexRLOptimizer(\n",
    "        env = env, \n",
    "        name = \"dqn\", \n",
    "        policy = \"MlpPolicy\", \n",
    "        seed = seed,\n",
    "        enable_checkpoint=False, \n",
    "        target_update_interval=1, \n",
    "        verbose=2, \n",
    "        batch_size=8)\n",
    "\n",
    "    print(\"...... Starting Training .......\")\n",
    "    if not os.path.exists(f\"model_checkpoints/best_model.zip\"):\n",
    "        opt.train(10000, log_interval=1)\n",
    "        opt.save(path = 'model_checkpoints')\n",
    "    print(\"------Training Completed--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mixed integer linear programming (MILP) and Simulated Annealing does not require training, hence the code for the MILP and SA section is shown directly while testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Testing Pipeline for the algorithms :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Test Data and Reinitialization: \n",
    "Now, we need to reinitiailize the grid object with the test dataset and change the respective decision unit contracts from the environment, so as to make the environment test ready!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read test data having emissions & prices values of dataset\n",
    "#load forecast and actual data for testing/inference \n",
    "forecast_df = pd.read_csv(\"/home/akshayn/main_encortex/data/UK_data_2020_meanprev_shortened.csv\")\n",
    "actual_df = pd.read_csv(\"/home/akshayn/main_encortex/data/UK_data_2020_actuals_shortened.csv\")\n",
    "\n",
    "# forecast_df = UKPricesEmissionsData(train=False, forecasts=True) \n",
    "# actual_df = UKPricesEmissionsData(train=False, forecasts=False)\n",
    "\n",
    "forecast_df[['emissions', 'prices']]  = forecast_df[['emissions', 'prices']].apply(lambda x: np.float32(x))\n",
    "actual_df[['emissions', 'prices']]  = actual_df[['emissions', 'prices']].apply(lambda x: np.float32(x))\n",
    "\n",
    "#parse the test data to the MarketData backend\n",
    "grid_data = MarketData.parse_backend(\n",
    "    3,\n",
    "    True,\n",
    "    3,\n",
    "    3,\n",
    "    np.timedelta64(\"5\", \"m\"),\n",
    "    price_forecast=DFBackend(forecast_df['prices'], forecast_df['timestamps']),\n",
    "    price_actual=DFBackend(actual_df['prices'], actual_df['timestamps']),\n",
    "    carbon_emissions_forecast=DFBackend(forecast_df['emissions'], forecast_df['timestamps']),\n",
    "    carbon_emissions_actual=DFBackend(actual_df['emissions'], actual_df['timestamps']),\n",
    "    carbon_prices_forecast=DFBackend(forecast_df['prices'], forecast_df['timestamps']),\n",
    "    carbon_prices_actual=DFBackend(actual_df['prices'], actual_df['timestamps']),\n",
    "    volume_forecast=DFBackend(None, None),\n",
    "    volume_actual=DFBackend(None, None),\n",
    ")\n",
    "\n",
    "grid.data = grid_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The following code snippet generates results on the training dataset using MILP optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restricted license - for non-production use only - expires 2024-10-28\n"
     ]
    }
   ],
   "source": [
    "# generate test results for MILP\n",
    "# Code for MILP to generate results on the training dataset: \n",
    "if milp_flag:\n",
    "    done = False\n",
    "    time = np.datetime64(\"2020-01-01T00:00\")\n",
    "    opt = MILPOptimizer(env)\n",
    "    # Run the optimizer on the environment\n",
    "    while not done:\n",
    "        obj, reward, time, done = opt.run(time)\n",
    "\n",
    "    battery_log = battery.action.action_log\n",
    "    environment_log = env.get_log()\n",
    "\n",
    "    current_socs =[]\n",
    "    predicted_actions = []\n",
    "    predicted_actions_power = []\n",
    "    for k,v in battery_log.items():\n",
    "        try:\n",
    "            v['current_soc'] = v['current_soc'][0]\n",
    "        except:\n",
    "            pass\n",
    "        current_socs.append(v['current_soc'])\n",
    "        predicted_actions.append(v['action'][0])\n",
    "        predicted_actions_power.append(v['power'][0])\n",
    "\n",
    "    results = create_dataframe(current_socs, predicted_actions, predicted_actions_power, environment_log['Carbon Emission'], environment_log['Price'], environment_log['Reward Carbon'], environment_log['Reward Cost'], environment_log['Reward'], environment_log['Reward Carbon'], environment_log['Reward'])\n",
    "    results.to_csv(dir_path+\"testdf_MILP.csv\", index=False)\n",
    "    #@TODO MR: Saving stuff, not sure how to handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Next, we load the saved trained DRL model to generate inference results on the same training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate results for RL test data\n",
    "if not (milp_flag):  \n",
    "    \n",
    "    #load the model first, if trained from the python script training_RL.py \n",
    "    opt.load('model_checkpoints/', 'best_model')\n",
    "    done = False\n",
    "    time = np.datetime64(\"2020-01-01T00:00\")\n",
    "    # Run the optimizer on the environment\n",
    "    while not done:\n",
    "        obj, reward, time, done = opt.run(time)\n",
    "\n",
    "    battery_log = battery.action.action_log\n",
    "    environment_log = env.get_log()\n",
    "\n",
    "    current_socs =[]\n",
    "    predicted_actions = []\n",
    "    predicted_actions_power = []\n",
    "    for k,v in battery_log.items():\n",
    "        try:\n",
    "            v['current_soc'] = v['current_soc'][0]\n",
    "        except:\n",
    "            pass\n",
    "        current_socs.append(v['current_soc'])\n",
    "        predicted_actions.append(v['action'][0])\n",
    "        predicted_actions_power.append(v['power'][0])\n",
    "\n",
    "    results = create_dataframe(current_socs, predicted_actions, predicted_actions_power, environment_log['Carbon Emission'], environment_log['Price'], environment_log['Reward Carbon'], environment_log['Reward Cost'], environment_log['Reward'], environment_log['Reward Carbon'], environment_log['Reward'])\n",
    "    results.to_csv(dir_path+\"testdf_DRL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Result Visualization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the visualization object from the environment by passing 2 arguments:\n",
    "- results_folder : The local folder name, where all the final results are stored\n",
    "- optimizers : A list of optimizers for which results are present in the results_folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi = env.visualize('/home/akshayn/main_encortex/docs/notebooks/results_UK/', ['MILP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, after running the following cell, provide the following as input to visualize the plots:\n",
    "- A multiselect option to choose between optimizers, so as to compare the final savings between two or more of them. To multiselect pressShift+ leftClick.\n",
    "- Choose between training/test file options from the radio buttons provided to visualize the schedules generated for each of the optimizers running on the user-input option of train/test file.\n",
    "- From the slider, select a day for which the battery schedules are to be shown\n",
    "- Click on the Plot button to plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Savings over the whole dataset\n",
       "- No. of days in the train dataset : 728\n",
       "- No. of days in the test dataset : 2\n",
       "\n",
       " \n",
       "\n",
       " \n",
       "Choose an Optimizer:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94411342d60b40f19c4639be1f0cd8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Optimizer:', index=(0,), options=('MILP', 'DRL', 'SA'), value=('MILP',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       " \n",
       "Choose the file to view results:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc025997bac5448f97684a454653037d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='File:', index=1, layout=Layout(width='max-content'), options=('Training File', 'Testâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       " \n",
       "Choose a day for checking schedules:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00677fc956dd4768a26f863440452b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, description='Day:', max=17472)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993c631c5cd54e4ead9ff4d5c53f1aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Plot', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352840673c904c5db25bd89b013a4cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "menu = widgets.SelectMultiple(\n",
    "       options=['MILP', 'DRL', 'SA'],\n",
    "       value=['MILP'],\n",
    "       description='Optimizer:',\n",
    "       disabled = False)\n",
    "rdbutton = widgets.RadioButtons(\n",
    "            options=['Training File', 'Test File'],\n",
    "            value='Test File', \n",
    "            layout={'width': 'max-content'},\n",
    "            description='File:',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "env.horizon = np.timedelta64(1, 'h')\n",
    "slider = widgets.IntSlider(\n",
    "                value=0,\n",
    "                min=0,\n",
    "                max=int(vi.tr_files[list(menu.value)[0]].shape[0]/(env.horizon/env.timestep)),\n",
    "                step=1,\n",
    "                description = \"Day:\")\n",
    "\n",
    "button = widgets.Button(description='Plot')\n",
    "out = widgets.Output()\n",
    "def on_button_clicked(b):\n",
    "    with out:\n",
    "        clear_output()    \n",
    "        vi.initial_plots(menu.value)\n",
    "\n",
    "        if rdbutton.value ==\"Test File\":\n",
    "            if slider.value > int(vi.te_files[list(menu.value)[0]].shape[0]/(env.get_schedule_timestep()/env.timestep)) :\n",
    "                print(\"Please choose a day lesser than Day 365, since its end of the test dataset\")\n",
    "                return\n",
    "\n",
    "        train_data = list(vi.tr_files.values()) \n",
    "        test_data = list(vi.te_files.values())\n",
    "        approach = list(menu.value)\n",
    "        if len(approach) == 1:\n",
    "            if approach[0] ==\"MILP\":\n",
    "                train_data=train_data[::2]\n",
    "                test_data=test_data[::2]\n",
    "            elif approach[0] == \"DRL\":\n",
    "                train_data=train_data[1::2]\n",
    "                test_data=test_data[1::2]\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        if rdbutton.value == 'Training File':             \n",
    "            title = f'Results for the Day {slider.value} of UK Data'\n",
    "            vi.plot_results(train_data, slider.value, int(env.get_schedule_timestep()/env.timestep), title, approach)\n",
    "        else:\n",
    "            title = f'Results for the Day {slider.value} of UK Data'\n",
    "            vi.plot_results(test_data, slider.value, int(env.get_schedule_timestep()/env.timestep), title, approach)\n",
    "        \n",
    "button.on_click(on_button_clicked)\n",
    "info = display(Markdown(\"\"\"# Savings over the whole dataset\n",
    "- No. of days in the train dataset : {}\n",
    "- No. of days in the test dataset : {}\n",
    "\\n \n",
    "\\n \n",
    "Choose an Optimizer:\"\"\".format(int(vi.tr_files[list(menu.value)[0]].shape[0]/(env.get_schedule_timestep()/env.timestep)),int(vi.te_files[list(menu.value)[0]].shape[0]/(env.get_schedule_timestep()/env.timestep)))))\n",
    "display(menu)\n",
    "display(Markdown('''\\n \\nChoose the file to view results:'''))\n",
    "display(rdbutton)\n",
    "display(Markdown('''\\n \\nChoose a day for checking schedules:'''))\n",
    "display(slider, button, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial bar charts provide a \"Total Savings\" comparison between train and test files along with multiple optimizers if selected. The left hand side bar plots denote the overall cost savings, whereas the right side plots signify the carbon savings.\n",
    "\n",
    "The plot below gives a clear indication of how the state of charge of the battery (green coloured line charts for multiple optimizers if selected) varies with the respective variations in Price (yellow plot) and carbon emissions (red plot). Based on the objective selected by the user, the price and carbon variations play a key role in deciding the charging and discharging schedules. For example, a common inference drawn from the schedules plot is when the prices are high, the battery discharges, whereas when the prices are low, the battery tends to charge from the utility grid, thus maximizing the profit for the consumer. Similar conclusion can be drawn for carbon arbitrage as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b6c4c21c342ccfe8bd746c79da7ba8541c7384424ed40863888a426e8468085"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00677fc956dd4768a26f863440452b55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "description": "Day:",
       "layout": "IPY_MODEL_6c0f90c93ddd40318e9004d4251f865f",
       "max": 17472,
       "style": "IPY_MODEL_caabcb1cd70d40a88829976f7a1b2cbb"
      }
     },
     "04b1cc3de94e40dcb4204cd490da9b29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SelectMultipleModel",
      "state": {
       "_options_labels": [
        "MILP",
        "DRL",
        "SA"
       ],
       "description": "Optimizer:",
       "index": [
        0
       ],
       "layout": "IPY_MODEL_6204e856ac6a49b3afb2689c6e4f3240",
       "rows": 5,
       "style": "IPY_MODEL_970759b2973c4fac9784eb336f12a476"
      }
     },
     "069e8998a4824986b09e6cad8e84d1b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "10ec3fe1f69e4ae5bf52cd1ca69751ae": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1c2cb83097f640d8a460ce43319a8d83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_10ec3fe1f69e4ae5bf52cd1ca69751ae",
       "style": "IPY_MODEL_37c6af842611474f8db33e4bbde4e97f"
      }
     },
     "1f6fe8897c0c46b288f384c76e3e8709": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "max-content"
      }
     },
     "275da07838c9425c889f94e8b974b684": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "292cb956949e4812aefdb7c349cd2d2c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2953cabed45145f0a011ffc557c0a6b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "RadioButtonsModel",
      "state": {
       "_options_labels": [
        "Training File",
        "Test File"
       ],
       "description": "File:",
       "index": 1,
       "layout": "IPY_MODEL_5db6efd48cd84acea070db32144d166a",
       "style": "IPY_MODEL_5c654e4e0fd64797abded51a39646e5b"
      }
     },
     "2ebff0fc0071445abfcc54051d3addd5": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_a1e43c27d2b94ffcaa9b8456b1a12d6c"
      }
     },
     "352840673c904c5db25bd89b013a4cb7": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_b8b874deb205477886add6aad093e0ba"
      }
     },
     "37c6af842611474f8db33e4bbde4e97f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "38e9378e174d445cae661b4834be23ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntSliderModel",
      "state": {
       "description": "Day:",
       "layout": "IPY_MODEL_e7fa4255abaf4e7eb20a6cd135bd8e23",
       "max": 728,
       "style": "IPY_MODEL_600e8b8c57e74a98b3aaa08c3b7d95ca"
      }
     },
     "396ca4d74ed0409c8aefbb491d9698cc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4f5fd4a9c8e7419489fb1998b802f650": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_f401c4b059974bd8818497dda27d66fe",
       "style": "IPY_MODEL_d1273c2fc51e4617bcada13009545d60"
      }
     },
     "5c654e4e0fd64797abded51a39646e5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5db6efd48cd84acea070db32144d166a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "max-content"
      }
     },
     "600e8b8c57e74a98b3aaa08c3b7d95ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "6204e856ac6a49b3afb2689c6e4f3240": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6c0f90c93ddd40318e9004d4251f865f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7a5db3af26804531bc7692d4d6989c44": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7d949c46c9c1492ebfa9fc228c778021": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7e52695116be499aa99af9e324c1f1de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_9322cc8944bc4d82af6d540500f6222d",
       "max": 1,
       "style": "IPY_MODEL_275da07838c9425c889f94e8b974b684"
      }
     },
     "7feeb515167b4f658a69eac59233ebda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4f5fd4a9c8e7419489fb1998b802f650",
        "IPY_MODEL_7e52695116be499aa99af9e324c1f1de"
       ],
       "layout": "IPY_MODEL_f6ca293b1bea4b6185c00ffe726683db"
      }
     },
     "80bdf76b63d54a81abf3d32c35558010": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Plot",
       "layout": "IPY_MODEL_97f85af090df4bee9f17c2e1ae9c6ed5",
       "style": "IPY_MODEL_ea8c342fb2ff4324b8f489d072f3ac22"
      }
     },
     "9322cc8944bc4d82af6d540500f6222d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "94411342d60b40f19c4639be1f0cd8b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SelectMultipleModel",
      "state": {
       "_options_labels": [
        "MILP",
        "DRL",
        "SA"
       ],
       "description": "Optimizer:",
       "index": [
        0
       ],
       "layout": "IPY_MODEL_292cb956949e4812aefdb7c349cd2d2c",
       "rows": 5,
       "style": "IPY_MODEL_7d949c46c9c1492ebfa9fc228c778021"
      }
     },
     "970759b2973c4fac9784eb336f12a476": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "97f85af090df4bee9f17c2e1ae9c6ed5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "993c631c5cd54e4ead9ff4d5c53f1aeb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Plot",
       "layout": "IPY_MODEL_7a5db3af26804531bc7692d4d6989c44",
       "style": "IPY_MODEL_b771ad18c1ad419199161b606cd96d94"
      }
     },
     "a1e43c27d2b94ffcaa9b8456b1a12d6c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a71ca249c6e347ff8f768409e04b803b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b5ed348fe98e42169c15b071b80eba49": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1c2cb83097f640d8a460ce43319a8d83",
        "IPY_MODEL_e30dd4f54adc4647ab80dcb555567c0d"
       ],
       "layout": "IPY_MODEL_cb4af702085b42f28af362ffdea4c2ef"
      }
     },
     "b771ad18c1ad419199161b606cd96d94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "b8b874deb205477886add6aad093e0ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "caabcb1cd70d40a88829976f7a1b2cbb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "SliderStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cb4af702085b42f28af362ffdea4c2ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cc025997bac5448f97684a454653037d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "RadioButtonsModel",
      "state": {
       "_options_labels": [
        "Training File",
        "Test File"
       ],
       "description": "File:",
       "index": 1,
       "layout": "IPY_MODEL_1f6fe8897c0c46b288f384c76e3e8709",
       "style": "IPY_MODEL_069e8998a4824986b09e6cad8e84d1b2"
      }
     },
     "d1273c2fc51e4617bcada13009545d60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e30dd4f54adc4647ab80dcb555567c0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_396ca4d74ed0409c8aefbb491d9698cc",
       "max": 1,
       "style": "IPY_MODEL_a71ca249c6e347ff8f768409e04b803b"
      }
     },
     "e7fa4255abaf4e7eb20a6cd135bd8e23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ea8c342fb2ff4324b8f489d072f3ac22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "f401c4b059974bd8818497dda27d66fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f6ca293b1bea4b6185c00ffe726683db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
